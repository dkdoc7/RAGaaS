"""CLI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""

import uuid
from pathlib import Path
from typing import Optional

import click

from doc2onto.config import load_config, Config
from doc2onto.chunkers import OEChunker, RAGChunker
from doc2onto.extractors import LLMStubExtractor
from doc2onto.builders import TriGBuilder, ChunksBuilder, EntityRegistryBuilder
from doc2onto.loaders import FusekiLoader, MilvusLoader
from doc2onto.qa import QAReporter
from doc2onto.models.chunk import ChunkBatch


@click.group()
@click.version_option(version="0.1.0")
def main():
    """Doc2Onto: í•œêµ­ì–´ ë¬¸ì„œ â†’ ì˜¨í†¨ë¡œì§€(OWL/RDF) + RAG ê·¼ê±° ì—°ê²° íŒŒì´í”„ë¼ì¸"""
    pass


@main.command()
@click.option("--in", "input_dir", required=True, type=click.Path(exists=True), help="ì…ë ¥ ë¬¸ì„œ ë””ë ‰í† ë¦¬")
@click.option("--out", "output_dir", required=True, type=click.Path(), help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
@click.option("--config", "config_path", default="./config.yml", type=click.Path(), help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
@click.option("--dry-run", is_flag=True, help="ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—†ì´ íŒŒì¼ë§Œ ìƒì„±")
@click.option("--run-id", default=None, help="ì‹¤í–‰ ID (ê¸°ë³¸: ìë™ ìƒì„±)")
@click.option("--oe-chunk-size", default=None, type=int, help="OE-Chunk í¬ê¸° (ê¸°ë³¸: config ë˜ëŠ” 2000)")
@click.option("--oe-chunk-overlap", default=None, type=int, help="OE-Chunk ì˜¤ë²„ë© (ê¸°ë³¸: config ë˜ëŠ” 500)")
@click.option("--external-chunks", default=None, type=click.Path(exists=True), help="ì™¸ë¶€ ì²­í¬ íŒŒì¼ (RAGaaS chunks.jsonl)")
def build(
    input_dir: str, 
    output_dir: str, 
    config_path: str, 
    dry_run: bool, 
    run_id: Optional[str],
    oe_chunk_size: Optional[int],
    oe_chunk_overlap: Optional[int],
    external_chunks: Optional[str],
):
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: ë¬¸ì„œ â†’ TriG + chunks.jsonl ìƒì„±"""
    
    # ì„¤ì • ë¡œë“œ
    config = load_config(config_path)
    run_id = run_id or str(uuid.uuid4())[:8]
    
    # CLI íŒŒë¼ë¯¸í„°ë¡œ ì˜¤ë²„ë¼ì´ë“œ
    final_oe_size = oe_chunk_size or config.chunking.oe_chunk_size
    final_oe_overlap = oe_chunk_overlap or config.chunking.oe_chunk_overlap
    
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    click.echo(f"ğŸš€ Doc2Onto Pipeline (run_id: {run_id})")
    click.echo(f"   Input:  {input_path}")
    click.echo(f"   Output: {output_path}")
    click.echo(f"   Config: {config_path}")
    click.echo(f"   OE-Chunk: {final_oe_size} / overlap {final_oe_overlap}")
    if external_chunks:
        click.echo(f"   External Chunks: {external_chunks}")
    if dry_run:
        click.echo("   Mode:   DRY-RUN")
    
    # ì´ˆê¸°í™”
    oe_chunker = OEChunker(
        chunk_size=final_oe_size,
        chunk_overlap=final_oe_overlap,
        section_aware=config.chunking.oe_section_aware,
    )
    rag_chunker = RAGChunker(
        chunk_size=config.chunking.rag_chunk_size,
        chunk_overlap=config.chunking.rag_chunk_overlap,
    )
    
    # LLM ì¶”ì¶œê¸° ì„ íƒ
    if config.extraction.llm_model != "stub":
        from doc2onto.extractors.openai_extractor import OpenAIExtractor
        extractor = OpenAIExtractor(
            confidence_threshold=config.extraction.confidence_threshold,
            llm_endpoint=config.extraction.llm_endpoint,
            llm_model=config.extraction.llm_model,
            examples_path=config.extraction.examples_path,
        )
        click.echo(f"   LLM:    {config.extraction.llm_model}")
    else:
        extractor = LLMStubExtractor(
            confidence_threshold=config.extraction.confidence_threshold,
            llm_endpoint=config.extraction.llm_endpoint,
            llm_model=config.extraction.llm_model,
        )
    trig_builder = TriGBuilder(
        base_uri=config.ontology.base_uri,
        base_graph_uri=config.ontology.base_graph_uri,
        evidence_graph_prefix=config.ontology.evidence_graph_prefix,
    )
    chunks_builder = ChunksBuilder()
    registry_builder = EntityRegistryBuilder(base_uri=config.ontology.base_uri)
    qa_reporter = QAReporter(run_id=run_id)
    
    # ë™ì˜ì–´ ì‚¬ì „ ë¡œë“œ (synonyms.yaml)
    synonyms_path = Path("synonyms.yaml")
    if synonyms_path.exists():
        syn_count = registry_builder.load_synonyms_yaml(synonyms_path)
        click.echo(f"ğŸ“š Loaded synonyms: {syn_count} entities from {synonyms_path}")

    # ë¬¸ì„œ ì²˜ë¦¬
    doc_files = list(input_path.glob("*.txt"))
    if not doc_files:
        click.echo("âš ï¸  No .txt files found in input directory")
        return
    
    click.echo(f"\nğŸ“„ Processing {len(doc_files)} documents...")
    
    all_candidates_raw = []
    all_candidates_filtered = []
    
    for doc_file in doc_files:
        doc_id = doc_file.stem
        click.echo(f"   - {doc_id}")
        
        # 1. OE-Chunking
        oe_chunks = list(oe_chunker.chunk_file(doc_file, doc_id))
        
        # 2. RAG-Chunking (ì™¸ë¶€ ì²­í¬ ë˜ëŠ” ìì²´ ìƒì„±)
        rag_chunks = []
        external_chunk_map = {}  # offset -> chunk_id ë§¤í•‘
        
        if external_chunks:
            # ì™¸ë¶€ ì²­í¬ íŒŒì¼ ë¡œë“œ (RAGaaS)
            import json
            with open(external_chunks, "r", encoding="utf-8") as f:
                for line in f:
                    chunk = json.loads(line)
                    if chunk.get("doc_id") == doc_id:
                        from doc2onto.models.chunk import RAGChunk
                        rag_chunk = RAGChunk(
                            chunk_id=chunk.get("chunk_id", ""),
                            doc_id=chunk.get("doc_id", ""),
                            doc_ver=chunk.get("doc_ver", "v1"),
                            text=chunk.get("text", ""),
                            chunk_idx=chunk.get("chunk_idx", 0),
                            start_offset=chunk.get("start_offset"),
                            end_offset=chunk.get("end_offset"),
                            section_path=chunk.get("section_path"),
                            chunk_hash=chunk.get("chunk_hash", ""),
                        )
                        rag_chunks.append(rag_chunk)
                        # offset ë²”ìœ„ ë§¤í•‘
                        if rag_chunk.start_offset is not None:
                            external_chunk_map[(rag_chunk.start_offset, rag_chunk.end_offset)] = rag_chunk.chunk_id
        else:
            # ìì²´ RAG-Chunking
            for oe_chunk in oe_chunks:
                for rag_chunk in rag_chunker.chunk_text(
                    oe_chunk.text, 
                    doc_id, 
                    source_oe_chunk_idx=oe_chunk.chunk_idx,
                    base_offset=oe_chunk.start_offset or 0,
                    section_path=oe_chunk.section_path,
                ):
                    rag_chunks.append(rag_chunk)
        
        chunks_builder.chunks.extend(rag_chunks)
        
        # 3. í›„ë³´ ì¶”ì¶œ (OE-Chunkì—ì„œ)
        for oe_chunk in oe_chunks:
            raw_result = extractor.extract(oe_chunk, run_id)
            all_candidates_raw.append(raw_result)
            
            filtered_result = extractor.filter_by_confidence(raw_result)
            all_candidates_filtered.append(filtered_result)
            
            # TriG ë¹Œë”ì— ì¶”ê°€
            trig_builder.build_from_candidates(filtered_result, registry_builder.registry)
            
            # Evidence ì¶”ê°€ - ì™¸ë¶€ ì²­í¬ ë˜ëŠ” ìì²´ ì²­í¬ ë§¤ì¹­
            for triple in filtered_result.triples:
                if external_chunks and external_chunk_map:
                    # ì™¸ë¶€ ì²­í¬: OE-Chunk offsetìœ¼ë¡œ ë§¤ì¹­ë˜ëŠ” ì²­í¬ ì°¾ê¸°
                    oe_start = oe_chunk.start_offset or 0
                    oe_end = oe_chunk.end_offset or oe_start + len(oe_chunk.text)
                    matching_chunks = [
                        c for c in rag_chunks 
                        if c.start_offset is not None 
                        and c.start_offset >= oe_start 
                        and (c.end_offset or 0) <= oe_end
                    ]
                else:
                    # ìì²´ ì²­í¬: source_oe_chunk_idxë¡œ ë§¤ì¹­
                    matching_chunks = [c for c in rag_chunks if c.source_oe_chunk_idx == oe_chunk.chunk_idx]
                
                if matching_chunks:
                    trig_builder.add_evidence_triple(triple, matching_chunks[0], run_id)
            
            # ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
            registry_builder.register_from_candidates(filtered_result)
        
        # QA í†µê³„
        oe_avg_len = sum(len(c.text) for c in oe_chunks) / len(oe_chunks) if oe_chunks else 0
        rag_avg_len = sum(len(c.text) for c in rag_chunks) / len(rag_chunks) if rag_chunks else 0
        qa_reporter.add_document_stats(doc_id, len(oe_chunks), len(rag_chunks), oe_avg_len, rag_avg_len)
    
    # ì¶”ì¶œ í†µê³„
    total_raw = sum(r.total_candidates + r.total_triples for r in all_candidates_raw)
    total_filtered = sum(r.total_candidates + r.total_triples for r in all_candidates_filtered)
    total_classes = sum(len(r.classes) for r in all_candidates_filtered)
    total_props = sum(len(r.properties) for r in all_candidates_filtered)
    total_rels = sum(len(r.relations) for r in all_candidates_filtered)
    total_insts = sum(len(r.instances) for r in all_candidates_filtered)
    total_triples = sum(len(r.triples) for r in all_candidates_filtered)
    
    qa_reporter.add_extraction_stats(
        total_raw, total_filtered,
        classes=total_classes,
        properties=total_props,
        relations=total_rels,
        instances=total_insts,
        triples=total_triples,
    )
    qa_reporter.add_entity_stats(registry_builder.registry.total_entities)
    
    # ì¶œë ¥ ì €ì¥
    click.echo(f"\nğŸ’¾ Saving outputs...")
    
    trig_builder.serialize_base(output_path / "base.trig")
    click.echo(f"   âœ“ base.trig")
    
    trig_builder.serialize_evidence(output_path / "evidence.trig")
    click.echo(f"   âœ“ evidence.trig")
    
    chunks_count = chunks_builder.serialize(output_path / "chunks.jsonl")
    click.echo(f"   âœ“ chunks.jsonl ({chunks_count} chunks)")
    
    # candidates ì €ì¥
    import json
    with open(output_path / "candidates_raw.jsonl", "w", encoding="utf-8") as f:
        for r in all_candidates_raw:
            f.write(r.model_dump_json() + "\n")
    click.echo(f"   âœ“ candidates_raw.jsonl")
    
    with open(output_path / "candidates_filtered.jsonl", "w", encoding="utf-8") as f:
        for r in all_candidates_filtered:
            f.write(r.model_dump_json() + "\n")
    click.echo(f"   âœ“ candidates_filtered.jsonl")
    
    registry_builder.serialize(output_path / "entity_registry.json")
    click.echo(f"   âœ“ entity_registry.json")
    
    qa_reporter.save(output_path / "qa_report.md")
    click.echo(f"   âœ“ qa_report.md")
    
    click.echo(f"\nâœ… Pipeline complete!")
    click.echo(f"   Documents: {len(doc_files)}")
    click.echo(f"   RAG Chunks: {chunks_count}")
    click.echo(f"   Triples: {total_triples}")


@main.command("load-fuseki")
@click.option("--in", "input_dir", required=True, type=click.Path(exists=True), help="TriG íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬")
@click.option("--fuseki", required=True, help="Fuseki ì—”ë“œí¬ì¸íŠ¸ (e.g., http://localhost:3030)")
@click.option("--dataset", default="ds", help="Fuseki ë°ì´í„°ì…‹ ì´ë¦„")
@click.option("--dry-run", is_flag=True, help="ì‹¤ì œ ì—…ë¡œë“œ ì—†ì´ í™•ì¸ë§Œ")
def load_fuseki(input_dir: str, fuseki: str, dataset: str, dry_run: bool):
    """Fusekiì— TriG íŒŒì¼ ì—…ë¡œë“œ"""
    
    input_path = Path(input_dir)
    loader = FusekiLoader(endpoint=fuseki, dataset=dataset)
    
    click.echo(f"ğŸ“¤ Loading to Fuseki: {fuseki}/{dataset}")
    if dry_run:
        click.echo("   Mode: DRY-RUN")
    
    for trig_file in input_path.glob("*.trig"):
        result = loader.upload(trig_file, dry_run=dry_run)
        status = "âœ“" if result["success"] else "âœ—"
        click.echo(f"   {status} {trig_file.name}: {result['message']}")
    
    click.echo("âœ… Done!")


@main.command("load-milvus")
@click.option("--in", "chunks_path", required=True, type=click.Path(exists=True), help="chunks.jsonl íŒŒì¼ ê²½ë¡œ")
@click.option("--milvus", required=True, help="Milvus í˜¸ìŠ¤íŠ¸:í¬íŠ¸ (e.g., localhost:19530)")
@click.option("--collection", default="doc2onto_chunks", help="Milvus ì»¬ë ‰ì…˜ ì´ë¦„")
@click.option("--dry-run", is_flag=True, help="ì‹¤ì œ ì ì¬ ì—†ì´ í™•ì¸ë§Œ")
def load_milvus(chunks_path: str, milvus: str, collection: str, dry_run: bool):
    """Milvusì— ì²­í¬ ì ì¬"""
    
    host, port = milvus.split(":") if ":" in milvus else (milvus, "19530")
    loader = MilvusLoader(host=host, port=int(port), collection=collection)
    
    click.echo(f"ğŸ“¤ Loading to Milvus: {host}:{port}/{collection}")
    if dry_run:
        click.echo("   Mode: DRY-RUN")
    
    result = loader.load(chunks_path, dry_run=dry_run)
    status = "âœ“" if result["success"] else "âœ—"
    click.echo(f"   {status} {result['message']}")
    
    click.echo("âœ… Done!")


@main.command("load")
@click.option("--in", "input_dir", required=True, type=click.Path(exists=True), help="ì‚°ì¶œë¬¼ ë””ë ‰í† ë¦¬")
@click.option("--backend", default="fuseki", help="ê·¸ë˜í”„ ë°±ì—”ë“œ: fuseki, neo4j, fuseki,neo4j")
@click.option("--fuseki", default="http://localhost:3030", help="Fuseki ì—”ë“œí¬ì¸íŠ¸")
@click.option("--dataset", default="ds", help="Fuseki ë°ì´í„°ì…‹")
@click.option("--neo4j", "neo4j_uri", default="bolt://localhost:7687", help="Neo4j URI")
@click.option("--neo4j-user", default="neo4j", help="Neo4j ì‚¬ìš©ì")
@click.option("--neo4j-password", default="", help="Neo4j ë¹„ë°€ë²ˆí˜¸")
@click.option("--dry-run", is_flag=True, help="ì‹¤ì œ ì ì¬ ì—†ì´ í™•ì¸ë§Œ")
def load_graph(
    input_dir: str, 
    backend: str, 
    fuseki: str, 
    dataset: str,
    neo4j_uri: str,
    neo4j_user: str,
    neo4j_password: str,
    dry_run: bool
):
    """ê·¸ë˜í”„ DBì— ì ì¬ (Fuseki/Neo4j)"""
    from doc2onto.builders.neo4j_builder import Neo4jBuilder
    from doc2onto.loaders.neo4j_loader import Neo4jLoader
    
    input_path = Path(input_dir)
    backends = [b.strip() for b in backend.split(",")]
    
    click.echo(f"ğŸ“¤ Graph Load")
    click.echo(f"   Input:    {input_path}")
    click.echo(f"   Backends: {backends}")
    if dry_run:
        click.echo("   Mode:     DRY-RUN")
    
    # Fuseki ì ì¬
    if "fuseki" in backends:
        click.echo(f"\nğŸ”· Fuseki: {fuseki}/{dataset}")
        loader = FusekiLoader(endpoint=fuseki, dataset=dataset)
        
        for trig_file in input_path.glob("*.trig"):
            result = loader.upload(trig_file, dry_run=dry_run)
            status = "âœ“" if result["success"] else "âœ—"
            click.echo(f"   {status} {trig_file.name}: {result['message']}")
    
    # Neo4j ì ì¬
    if "neo4j" in backends:
        click.echo(f"\nğŸ”¶ Neo4j: {neo4j_uri}")
        
        # TriG â†’ Cypher ë³€í™˜
        builder = Neo4jBuilder()
        
        base_trig = input_path / "base.trig"
        if base_trig.exists():
            count = builder.load_trig(base_trig)
            click.echo(f"   âœ“ base.trig íŒŒì‹±: {count} íŠ¸ë¦¬í”Œ")
        
        evidence_trig = input_path / "evidence.trig"
        if evidence_trig.exists():
            count = builder.load_trig(evidence_trig)
            click.echo(f"   âœ“ evidence.trig íŒŒì‹±: {count} íŠ¸ë¦¬í”Œ")
        
        chunks_jsonl = input_path / "chunks.jsonl"
        if chunks_jsonl.exists():
            count = builder.load_chunks(chunks_jsonl)
            click.echo(f"   âœ“ chunks.jsonl íŒŒì‹±: {count} ì²­í¬")
        
        # Cypher ì €ì¥
        cypher_path = input_path / "neo4j_load.cypher"
        result = builder.serialize(cypher_path)
        click.echo(f"   âœ“ Cypher ìƒì„±: {result['nodes']} ë…¸ë“œ, {result['relationships']} ê´€ê³„")
        
        if not dry_run and neo4j_password:
            loader = Neo4jLoader(
                uri=neo4j_uri,
                user=neo4j_user,
                password=neo4j_password,
            )
            load_result = loader.execute_cypher_file(cypher_path, dry_run=False)
            status = "âœ“" if load_result["success"] else "âœ—"
            click.echo(f"   {status} Neo4j ì ì¬: {load_result['message']}")
            loader.close()
        else:
            click.echo(f"   â„¹ï¸  Cypher íŒŒì¼ ìƒì„±ë¨: {cypher_path}")
    
    click.echo("\nâœ… Done!")


@main.command("load-neo4j")
@click.option("--in", "cypher_path", required=True, type=click.Path(exists=True), help="Cypher íŒŒì¼ ê²½ë¡œ")
@click.option("--neo4j", "neo4j_uri", default="bolt://localhost:7687", help="Neo4j URI")
@click.option("--user", default="neo4j", help="Neo4j ì‚¬ìš©ì")
@click.option("--password", required=True, help="Neo4j ë¹„ë°€ë²ˆí˜¸")
@click.option("--clear", is_flag=True, help="ê¸°ì¡´ ë°ì´í„° ì‚­ì œ")
@click.option("--dry-run", is_flag=True, help="ì‹¤ì œ ì ì¬ ì—†ì´ í™•ì¸ë§Œ")
def load_neo4j(cypher_path: str, neo4j_uri: str, user: str, password: str, clear: bool, dry_run: bool):
    """Neo4jì— Cypher íŒŒì¼ ì‹¤í–‰"""
    from doc2onto.loaders.neo4j_loader import Neo4jLoader
    
    loader = Neo4jLoader(uri=neo4j_uri, user=user, password=password)
    
    click.echo(f"ğŸ“¤ Loading to Neo4j: {neo4j_uri}")
    if dry_run:
        click.echo("   Mode: DRY-RUN")
    
    conn = loader.connect()
    if not conn["success"]:
        click.echo(f"   âœ— ì—°ê²° ì‹¤íŒ¨: {conn['message']}")
        return
    click.echo(f"   âœ“ ì—°ê²° ì„±ê³µ")
    
    if clear:
        result = loader.clear(dry_run=dry_run)
        click.echo(f"   âœ“ ë°ì´í„° ì´ˆê¸°í™”: {result['message']}")
    
    result = loader.execute_cypher_file(cypher_path, dry_run=dry_run)
    status = "âœ“" if result["success"] else "âœ—"
    click.echo(f"   {status} {result['message']}")
    
    if not dry_run:
        stats = loader.get_stats()
        if stats["success"]:
            click.echo(f"   ğŸ“Š ë…¸ë“œ: {stats['nodes']}, ê´€ê³„: {stats['relationships']}")
    
    loader.close()
    click.echo("âœ… Done!")


@main.command("promote")
@click.option("--in", "input_dir", required=True, type=click.Path(exists=True), help="KG ì‚°ì¶œë¬¼ ë””ë ‰í† ë¦¬ (base.trig, evidence.trig)")
@click.option("--out", "output_dir", default="./ontology", type=click.Path(), help="Ontology ì¶œë ¥ ë””ë ‰í† ë¦¬")
@click.option("--confidence", default=0.85, type=float, help="ìŠ¹ê²© ìµœì†Œ confidence (ê¸°ë³¸: 0.85)")
@click.option("--min-evidence", default=2, type=int, help="ìµœì†Œ ê·¼ê±° ìˆ˜ (ê¸°ë³¸: 2)")
@click.option("--version", "onto_version", default="v1.0", help="Ontology ë²„ì „")
@click.option("--dry-run", is_flag=True, help="ì‹¤ì œ ì €ì¥ ì—†ì´ í™•ì¸ë§Œ")
def promote(
    input_dir: str,
    output_dir: str,
    confidence: float,
    min_evidence: int,
    onto_version: str,
    dry_run: bool,
):
    """KG â†’ Ontology ìŠ¹ê²©: 7ë‹¨ê³„ íŒŒì´í”„ë¼ì¸"""
    from doc2onto.promoters.ontology_promoter import OntologyPromoter
    
    input_path = Path(input_dir)
    base_trig = input_path / "base.trig"
    evidence_trig = input_path / "evidence.trig"
    
    if not base_trig.exists():
        click.echo(f"âŒ base.trig íŒŒì¼ ì—†ìŒ: {base_trig}")
        return
    
    click.echo(f"ğŸ”„ Ontology Promotion")
    click.echo(f"   Input:      {input_path}")
    click.echo(f"   Output:     {output_dir}")
    click.echo(f"   Confidence: â‰¥ {confidence}")
    click.echo(f"   Min Evidence: {min_evidence}")
    click.echo(f"   Version:    {onto_version}")
    if dry_run:
        click.echo("   Mode:       DRY-RUN")
    
    promoter = OntologyPromoter(
        confidence_threshold=confidence,
        min_evidence_count=min_evidence,
        detect_cycles=True,
        remove_hypothetical=True,
    )
    
    click.echo("\nğŸ“Š Processing...")
    
    result = promoter.promote(
        base_trig=base_trig,
        evidence_trig=evidence_trig if evidence_trig.exists() else None,
        output_dir=output_dir,
        version=onto_version,
        dry_run=dry_run,
    )
    
    stats = result["stats"]
    validation = result["validation"]
    
    click.echo(f"\nğŸ“ˆ Statistics:")
    click.echo(f"   ì…ë ¥ íŠ¸ë¦¬í”Œ: {stats['input_triples']}")
    click.echo(f"   Step 1 í›„ë³´: {stats['step1_candidates']}")
    click.echo(f"   Step 2 í´ë˜ìŠ¤: {stats['step2_classes']}, ì†ì„±: {stats['step2_properties']}")
    click.echo(f"   Step 3 cycle ì œê±°: {stats['step3_cycles_removed']}")
    click.echo(f"   Step 5 evidence ì œê±°: {stats['step5_evidence_removed']}")
    click.echo(f"   ì¶œë ¥ íŠ¸ë¦¬í”Œ: {stats['output_triples']}")
    
    click.echo(f"\nğŸ” Validation:")
    status = "âœ“" if validation["consistent"] else "âœ—"
    click.echo(f"   {status} Consistent: {validation['consistent']}")
    if validation["errors"]:
        for err in validation["errors"]:
            click.echo(f"   âš ï¸  {err}")
    
    if not dry_run:
        click.echo(f"\nğŸ’¾ Outputs:")
        click.echo(f"   âœ“ {result.get('ontology_path')}")
        click.echo(f"   âœ“ {result.get('schema_path')}")
        click.echo(f"   âœ“ {result.get('report_path')}")
    
    click.echo("\nâœ… Promotion complete!")


@main.group()
def registry():
    """ë™ì˜ì–´ ì‚¬ì „(Entity Registry) ê´€ë¦¬"""
    pass


@registry.command("list")
@click.option("--in", "registry_path", default="./out/entity_registry.json", help="ë ˆì§€ìŠ¤íŠ¸ë¦¬ íŒŒì¼ ê²½ë¡œ")
@click.option("--query", "-q", help="ê²€ìƒ‰ì–´ (ë¼ë²¨ ë˜ëŠ” URI)")
def registry_list(registry_path: str, query: Optional[str]):
    """ì—”í‹°í‹° ëª©ë¡ ì¡°íšŒ"""
    from doc2onto.builders.entity_registry import EntityRegistryBuilder
    
    path = Path(registry_path)
    if not path.exists():
        click.echo(f"âŒ File not found: {path}")
        return

    builder = EntityRegistryBuilder.load(path)
    
    click.echo(f"ğŸ“– Registry: {path}")
    click.echo(f"   Total Entities: {builder.registry.total_entities}")
    click.echo("-" * 60)
    
    count = 0
    for uri, entry in builder.registry.entries.items():
        if query:
            match = query in entry.canonical_label or \
                    query in uri or \
                    any(query in alias for alias in entry.labels)
            if not match:
                continue
        
        click.echo(f"[{entry.entity_type}] {entry.canonical_label}")
        click.echo(f"  URI: {uri}")
        if len(entry.labels) > 1:
            aliases = [l for l in entry.labels if l != entry.canonical_label]
            click.echo(f"  Aliases: {', '.join(aliases)}")
        click.echo("")
        count += 1
        
        if count >= 50:
            click.echo("... (First 50 results shown)")
            break
            
    if count == 0:
        click.echo("Thinking... No entities found.")


@registry.command("add")
@click.option("--in", "registry_path", default="./out/entity_registry.json", help="ë ˆì§€ìŠ¤íŠ¸ë¦¬ íŒŒì¼ ê²½ë¡œ")
@click.option("--label", required=True, help="ì—”í‹°í‹° ë¼ë²¨ (ì •ê·œí˜•)")
@click.option("--type", "entity_type", default="instance", type=click.Choice(['class', 'instance', 'property', 'relation']), help="ì—”í‹°í‹° ìœ í˜•")
@click.option("--uri", help="ì—”í‹°í‹° URI (ë¯¸ì§€ì • ì‹œ ìë™ìƒì„±)")
@click.option("--alias", multiple=True, help="ë™ì˜ì–´/ë³„ì¹­ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)")
def registry_add(registry_path: str, label: str, entity_type: str, uri: Optional[str], alias: tuple):
    """ìƒˆ ì—”í‹°í‹° ë“±ë¡"""
    from doc2onto.builders.entity_registry import EntityRegistryBuilder
    
    path = Path(registry_path)
    
    # Load or Create
    if path.exists():
        builder = EntityRegistryBuilder.load(path)
    else:
        click.echo(f"ğŸ†• Creating new registry at {path}")
        # Need base_uri from somewhere or default
        builder = EntityRegistryBuilder() 

    if not uri:
        # Use internal helper if available, or just construct
        uri = builder._to_uri(label, entity_type)
    
    entry = builder.registry.register(
        uri=uri,
        label=label,
        entity_type=entity_type,
        run_id="manual-cli",
        aliases=list(alias)
    )
    
    builder.serialize(path)
    
    click.echo(f"âœ… Added Entity: {label}")
    click.echo(f"   URI: {uri}")
    click.echo(f"   Aliases: {entry.labels}")


@registry.command("alias")
@click.option("--in", "registry_path", default="./out/entity_registry.json", help="ë ˆì§€ìŠ¤íŠ¸ë¦¬ íŒŒì¼ ê²½ë¡œ")
@click.option("--label", required=True, help="ëŒ€ìƒ ì—”í‹°í‹° ë¼ë²¨ (ì •ê·œí˜•)")
@click.option("--add", "aliases", required=True, multiple=True, help="ì¶”ê°€í•  ë™ì˜ì–´")
def registry_alias(registry_path: str, label: str, aliases: tuple):
    """ê¸°ì¡´ ì—”í‹°í‹°ì— ë™ì˜ì–´ ì¶”ê°€"""
    from doc2onto.builders.entity_registry import EntityRegistryBuilder
    
    path = Path(registry_path)
    if not path.exists():
        click.echo(f"âŒ File not found: {path}")
        return
        
    builder = EntityRegistryBuilder.load(path)
    
    uri = builder.registry.lookup_by_label(label)
    if not uri:
        click.echo(f"âŒ Entity not found with label: {label}")
        return
        
    success_count = 0
    for alias in aliases:
        if builder.add_alias(label, alias):
            click.echo(f"   + Added alias: {alias}")
            success_count += 1
        else:
            click.echo(f"   - Failed/Exists: {alias}")
            
    if success_count > 0:
        builder.serialize(path)
        click.echo(f"âœ… Updated registry saved to {path}")


@main.group()
def examples():
    """Few-shot ì˜ˆì œ(extraction_examples.yaml) ê´€ë¦¬"""
    pass


@examples.command("list")
@click.option("--in", "file_path", default="./extraction_examples.yaml", help="ì˜ˆì œ íŒŒì¼ ê²½ë¡œ")
def examples_list(file_path: str):
    """ë“±ë¡ëœ ì˜ˆì œ ëª©ë¡ ì¡°íšŒ"""
    import yaml
    
    path = Path(file_path)
    if not path.exists():
        click.echo(f"âŒ File not found: {path}")
        return
        
    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f) or []
        
    click.echo(f"ğŸ“– Examples: {path}")
    click.echo(f"   Total Count: {len(data)}")
    click.echo("-" * 60)
    
    for idx, item in enumerate(data):
        text = item.get("text", "")
        triples = item.get("triples", [])
        click.echo(f"[{idx}] {text[:60]}{'...' if len(text)>60 else ''}")
        for t in triples:
            click.echo(f"    - ({t.get('subject')}) --[{t.get('predicate')}]--> ({t.get('object')})")
        click.echo("")


@examples.command("add")
@click.option("--in", "file_path", default="./extraction_examples.yaml", help="ì˜ˆì œ íŒŒì¼ ê²½ë¡œ")
@click.option("--text", required=True, help="ì˜ˆì œ í…ìŠ¤íŠ¸")
@click.option("--triple", "triples_raw", multiple=True, help="íŠ¸ë¦¬í”Œ (í˜•ì‹: ì£¼ì–´,ì„œìˆ ì–´,ëª©ì ì–´)")
def examples_add(file_path: str, text: str, triples_raw: tuple):
    """ìƒˆ ì˜ˆì œ ì¶”ê°€ (íŠ¸ë¦¬í”Œì€ ì‰¼í‘œë¡œ êµ¬ë¶„)"""
    import yaml
    
    path = Path(file_path)
    data = []
    
    if path.exists():
        with open(path, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f) or []
            
    new_triples = []
    for t_str in triples_raw:
        parts = [p.strip() for p in t_str.split(",")]
        if len(parts) != 3:
            click.echo(f"âš ï¸  Invalid triple format (skipped): {t_str}. Use 'Subject, Predicate, Object'")
            continue
        new_triples.append({
            "subject": parts[0],
            "predicate": parts[1],
            "object": parts[2]
        })
        
    if not new_triples:
        click.echo("âŒ No valid triples provided.")
        return
        
    new_entry = {
        "text": text,
        "triples": new_triples
    }
    
    data.append(new_entry)
    
    with open(path, "w", encoding="utf-8") as f:
        yaml.safe_dump(data, f, allow_unicode=True, sort_keys=False)
        
    click.echo(f"âœ… Added new example with {len(new_triples)} triples.")


@examples.command("remove")
@click.option("--in", "file_path", default="./extraction_examples.yaml", help="ì˜ˆì œ íŒŒì¼ ê²½ë¡œ")
@click.option("--index", required=True, type=int, help="ì‚­ì œí•  ì˜ˆì œ ì¸ë±ìŠ¤ (list ëª…ë ¹ì–´ë¡œ í™•ì¸)")
def examples_remove(file_path: str, index: int):
    """ì˜ˆì œ ì‚­ì œ"""
    import yaml
    
    path = Path(file_path)
    if not path.exists():
        click.echo(f"âŒ File not found: {path}")
        return
        
    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f) or []
        
    if index < 0 or index >= len(data):
        click.echo(f"âŒ Invalid index: {index}. Valid range: 0 ~ {len(data)-1}")
        return
        
    removed = data.pop(index)
    
    with open(path, "w", encoding="utf-8") as f:
        yaml.safe_dump(data, f, allow_unicode=True, sort_keys=False)
        
    click.echo(f"âœ… Removed example [{index}]: {removed.get('text', '')[:30]}...")


if __name__ == "__main__":
    main()

